diff --git a/src/services/code-index/processors/file-watcher.ts b/src/services/code-index/processors/file-watcher.ts
index 6dc1cd18..c798ec57 100644
--- a/src/services/code-index/processors/file-watcher.ts
+++ b/src/services/code-index/processors/file-watcher.ts
@@ -7,7 +7,7 @@ import {
 	INITIAL_RETRY_DELAY_MS,
 } from "../constants"
 import { createHash } from "crypto"
-import { RooIgnoreController } from "../../../core/ignore/RooIgnoreController"
+import { RooIgnoreController, CodebaseIgnoreController } from "../../../core/ignore/RooIgnoreController"
 import { v5 as uuidv5 } from "uuid"
 import { Ignore } from "ignore"
 import { scannerExtensions } from "../shared/supported-extensions"
@@ -18,8 +18,9 @@ import {
 	IVectorStore,
 	PointStruct,
 	BatchProcessingSummary,
+	ICodeParser,
 } from "../interfaces"
-import { codeParser } from "./parser"
+// import { codeParser } from "./parser"
 import { CacheManager } from "../cache-manager"
 import { generateNormalizedAbsolutePath, generateRelativeFilePath } from "../shared/get-relative-path"
 import { isPathInIgnoredDirectory } from "../../glob/ignore-utils"
@@ -34,6 +35,7 @@ export class FileWatcher implements IFileWatcher {
 	private ignoreInstance?: Ignore
 	private fileWatcher?: vscode.FileSystemWatcher
 	private ignoreController: RooIgnoreController
+	private cbIgnoreController: CodebaseIgnoreController
 	private accumulatedEvents: Map<string, { uri: vscode.Uri; type: "create" | "change" | "delete" }> = new Map()
 	private batchProcessDebounceTimer?: NodeJS.Timeout
 	private readonly BATCH_DEBOUNCE_DELAY_MS = 500
@@ -67,15 +69,16 @@ export class FileWatcher implements IFileWatcher {
 	 * @param workspacePath Path to the workspace
 	 * @param context VS Code extension context
 	 * @param embedder Optional embedder
-	 * @param vectorStore Optional vector store
+	 * @param qdrantClient Optional vector store
 	 * @param cacheManager Cache manager
 	 */
 	constructor(
 		private workspacePath: string,
 		private context: vscode.ExtensionContext,
 		private readonly cacheManager: CacheManager,
+		private readonly codeParser: ICodeParser,
 		private embedder?: IEmbedder,
-		private vectorStore?: IVectorStore,
+		private qdrantClient?: IVectorStore,
 		ignoreInstance?: Ignore,
 		ignoreController?: RooIgnoreController,
 	) {
@@ -83,6 +86,7 @@ export class FileWatcher implements IFileWatcher {
 		if (ignoreInstance) {
 			this.ignoreInstance = ignoreInstance
 		}
+		this.cbIgnoreController = new CodebaseIgnoreController(workspacePath)
 	}
 
 	/**
@@ -190,9 +194,9 @@ export class FileWatcher implements IFileWatcher {
 			}
 		}
 
-		if (allPathsToClearFromDB.size > 0 && this.vectorStore) {
+		if (allPathsToClearFromDB.size > 0 && this.qdrantClient) {
 			try {
-				await this.vectorStore.deletePointsByMultipleFilePaths(Array.from(allPathsToClearFromDB))
+				await this.qdrantClient.deletePointsByMultipleFilePaths(Array.from(allPathsToClearFromDB))
 
 				for (const path of pathsToExplicitlyDelete) {
 					this.cacheManager.deleteHash(path)
@@ -204,15 +208,20 @@ export class FileWatcher implements IFileWatcher {
 						currentFile: path,
 					})
 				}
-			} catch (error) {
-				overallBatchError = error as Error
+			} catch (error: any) {
+				const errorStatus = error?.status || error?.response?.status || error?.statusCode
+				const errorMessage = error instanceof Error ? error.message : String(error)
+
 				// Log telemetry for deletion error
 				TelemetryService.instance.captureEvent(TelemetryEventName.CODE_INDEX_ERROR, {
-					error: sanitizeErrorMessage(overallBatchError.message),
+					error: sanitizeErrorMessage(errorMessage),
 					location: "deletePointsByMultipleFilePaths",
 					errorType: "deletion_error",
+					errorStatus: errorStatus,
 				})
 
+				// Mark all paths as error
+				overallBatchError = error as Error
 				for (const path of pathsToExplicitlyDelete) {
 					batchResults.push({ path, status: "error", error: error as Error })
 					processedCountInBatch++
@@ -334,7 +343,7 @@ export class FileWatcher implements IFileWatcher {
 		batchResults: FileProcessingResult[],
 		overallBatchError?: Error,
 	): Promise<Error | undefined> {
-		if (pointsForBatchUpsert.length > 0 && this.vectorStore && !overallBatchError) {
+		if (pointsForBatchUpsert.length > 0 && this.qdrantClient && !overallBatchError) {
 			try {
 				for (let i = 0; i < pointsForBatchUpsert.length; i += BATCH_SEGMENT_THRESHOLD) {
 					const batch = pointsForBatchUpsert.slice(i, i + BATCH_SEGMENT_THRESHOLD)
@@ -343,7 +352,7 @@ export class FileWatcher implements IFileWatcher {
 
 					while (retryCount < MAX_BATCH_RETRIES) {
 						try {
-							await this.vectorStore.upsertPoints(batch)
+							await this.qdrantClient.upsertPoints(batch)
 							break
 						} catch (error) {
 							upsertError = error as Error
@@ -497,7 +506,7 @@ export class FileWatcher implements IFileWatcher {
 
 			// Check if file should be ignored
 			const relativeFilePath = generateRelativeFilePath(filePath, this.workspacePath)
-			if (
+			if (!this.cbIgnoreController.validateAccess(filePath) ||
 				!this.ignoreController.validateAccess(filePath) ||
 				(this.ignoreInstance && this.ignoreInstance.ignores(relativeFilePath))
 			) {
@@ -535,7 +544,7 @@ export class FileWatcher implements IFileWatcher {
 			}
 
 			// Parse file
-			const blocks = await codeParser.parseFile(filePath, { content, fileHash: newHash })
+			const blocks = await this.codeParser.parseFile(filePath, { content, fileHash: newHash })
 
 			// Prepare points for batch processing
 			let pointsToUpsert: PointStruct[] = []
diff --git a/src/services/code-index/processors/index.ts b/src/services/code-index/processors/index.ts
index c244d9b8..8b018f6e 100644
--- a/src/services/code-index/processors/index.ts
+++ b/src/services/code-index/processors/index.ts
@@ -1,3 +1,4 @@
 export * from "./parser"
 export * from "./scanner"
 export * from "./file-watcher"
+export * from "./parser-riddler"
diff --git a/src/services/code-index/processors/parser.ts b/src/services/code-index/processors/parser.ts
index 96d747c4..8611884a 100644
--- a/src/services/code-index/processors/parser.ts
+++ b/src/services/code-index/processors/parser.ts
@@ -5,7 +5,7 @@ import { Node } from "web-tree-sitter"
 import { LanguageParser, loadRequiredLanguageParsers } from "../../tree-sitter/languageParser"
 import { parseMarkdown } from "../../tree-sitter/markdownParser"
 import { ICodeParser, CodeBlock } from "../interfaces"
-import { scannerExtensions } from "../shared/supported-extensions"
+import { scannerExtensions, shouldUseFallbackChunking } from "../shared/supported-extensions"
 import { MAX_BLOCK_CHARS, MIN_BLOCK_CHARS, MIN_CHUNK_REMAINDER_CHARS, MAX_CHARS_TOLERANCE_FACTOR } from "../constants"
 import { TelemetryService } from "@roo-code/telemetry"
 import { TelemetryEventName } from "@roo-code/types"
@@ -101,6 +101,11 @@ export class CodeParser implements ICodeParser {
 			return this.parseMarkdownContent(filePath, content, fileHash, seenSegmentHashes)
 		}
 
+		// Check if this extension should use fallback chunking
+		if (shouldUseFallbackChunking(`.${ext}`)) {
+			return this._performFallbackChunking(filePath, content, fileHash, seenSegmentHashes)
+		}
+
 		// Check if we already have the parser loaded
 		if (!this.loadedParsers[ext]) {
 			const pendingLoad = this.pendingLoads.get(ext)
diff --git a/src/services/code-index/processors/scanner.ts b/src/services/code-index/processors/scanner.ts
index 3203076d..fc6f3779 100644
--- a/src/services/code-index/processors/scanner.ts
+++ b/src/services/code-index/processors/scanner.ts
@@ -1,6 +1,6 @@
 import { listFiles } from "../../glob/list-files"
 import { Ignore } from "ignore"
-import { RooIgnoreController } from "../../../core/ignore/RooIgnoreController"
+import { RooIgnoreController, CodebaseIgnoreController } from "../../../core/ignore/RooIgnoreController"
 import { stat } from "fs/promises"
 import * as path from "path"
 import { generateNormalizedAbsolutePath, generateRelativeFilePath } from "../shared/get-relative-path"
@@ -30,6 +30,9 @@ import { TelemetryService } from "@roo-code/telemetry"
 import { TelemetryEventName } from "@roo-code/types"
 import { sanitizeErrorMessage } from "../shared/validation-helpers"
 
+import { RiddlerEmbedder } from "../embedders/embedding-riddler"
+
+
 export class DirectoryScanner implements IDirectoryScanner {
 	constructor(
 		private readonly embedder: IEmbedder,
@@ -58,7 +61,7 @@ export class DirectoryScanner implements IDirectoryScanner {
 		const scanWorkspace = getWorkspacePathForContext(directoryPath)
 
 		// Get all files recursively (handles .gitignore automatically)
-		const [allPaths, _] = await listFiles(directoryPath, true, MAX_LIST_FILES_LIMIT_CODE_INDEX)
+		const [allPaths, _] = await listFiles(directoryPath, true, MAX_LIST_FILES_LIMIT_CODE_INDEX + 1000)
 
 		// Filter out directories (marked with trailing '/')
 		const filePaths = allPaths.filter((p) => !p.endsWith("/"))
@@ -69,10 +72,18 @@ export class DirectoryScanner implements IDirectoryScanner {
 		await ignoreController.initialize()
 
 		// Filter paths using .rooignore
-		const allowedPaths = ignoreController.filterPaths(filePaths)
+		let allowedPaths = ignoreController.filterPaths(filePaths)
+
+		// Initialize RooIgnoreController if not provided
+		const cbignoreController = new CodebaseIgnoreController(directoryPath)
+
+		await cbignoreController.initialize()
+
+		// Filter paths using .rooignore
+		allowedPaths = cbignoreController.filterPaths(allowedPaths)
 
 		// Filter by supported extensions, ignore patterns, and excluded directories
-		const supportedPaths = allowedPaths.filter((filePath) => {
+		let supportedPaths = allowedPaths.filter((filePath) => {
 			const ext = path.extname(filePath).toLowerCase()
 			const relativeFilePath = generateRelativeFilePath(filePath, scanWorkspace)
 
@@ -84,6 +95,14 @@ export class DirectoryScanner implements IDirectoryScanner {
 			return scannerExtensions.includes(ext) && !this.ignoreInstance.ignores(relativeFilePath)
 		})
 
+		const real_limit = this.embedder instanceof RiddlerEmbedder ? 800 : MAX_LIST_FILES_LIMIT_CODE_INDEX
+
+		// Sort files by most recent activity (modified, created, or accessed time)
+		// This ensures recently active files are prioritized for indexing
+		const sortedPaths = await this.sortFilesByRecentActivity(supportedPaths)
+
+		supportedPaths = sortedPaths.slice(0, real_limit)
+
 		// Initialize tracking variables
 		const processedFiles = new Set<string>()
 		let processedCount = 0
@@ -153,7 +172,7 @@ export class DirectoryScanner implements IDirectoryScanner {
 									addedBlocksFromFile = true
 
 									// Check if batch threshold is met
-									if (currentBatchBlocks.length >= BATCH_SEGMENT_THRESHOLD) {
+									if (currentBatchBlocks.length >= (this.embedder instanceof RiddlerEmbedder?1:BATCH_SEGMENT_THRESHOLD)) {
 										// Wait if we've reached the maximum pending batches
 										while (pendingBatchCount >= MAX_PENDING_BATCHES) {
 											// Wait for at least one batch to complete
@@ -281,17 +300,24 @@ export class DirectoryScanner implements IDirectoryScanner {
 					try {
 						await this.qdrantClient.deletePointsByFilePath(cachedFilePath)
 						await this.cacheManager.deleteHash(cachedFilePath)
-					} catch (error) {
+					} catch (error: any) {
+						const errorStatus = error?.status || error?.response?.status || error?.statusCode
+						const errorMessage = error instanceof Error ? error.message : String(error)
+
 						console.error(
 							`[DirectoryScanner] Failed to delete points for ${cachedFilePath} in workspace ${scanWorkspace}:`,
 							error,
 						)
+
 						TelemetryService.instance.captureEvent(TelemetryEventName.CODE_INDEX_ERROR, {
-							error: sanitizeErrorMessage(error instanceof Error ? error.message : String(error)),
+							error: sanitizeErrorMessage(errorMessage),
 							stack: error instanceof Error ? sanitizeErrorMessage(error.stack || "") : undefined,
 							location: "scanDirectory:deleteRemovedFiles",
+							errorStatus: errorStatus,
 						})
+
 						if (onError) {
+							// Report error to error handler
 							onError(
 								error instanceof Error
 									? new Error(
@@ -304,7 +330,8 @@ export class DirectoryScanner implements IDirectoryScanner {
 										),
 							)
 						}
-						// Decide if we should re-throw or just log
+						// Log error and continue processing instead of re-throwing
+						console.error(`Failed to delete points for removed file: ${cachedFilePath}`, error)
 					}
 				}
 			}
@@ -347,25 +374,30 @@ export class DirectoryScanner implements IDirectoryScanner {
 				if (uniqueFilePaths.length > 0) {
 					try {
 						await this.qdrantClient.deletePointsByMultipleFilePaths(uniqueFilePaths)
-					} catch (deleteError) {
+					} catch (deleteError: any) {
+						const errorStatus =
+							deleteError?.status || deleteError?.response?.status || deleteError?.statusCode
+						const errorMessage = deleteError instanceof Error ? deleteError.message : String(deleteError)
+
 						console.error(
 							`[DirectoryScanner] Failed to delete points for ${uniqueFilePaths.length} files before upsert in workspace ${scanWorkspace}:`,
 							deleteError,
 						)
+
 						TelemetryService.instance.captureEvent(TelemetryEventName.CODE_INDEX_ERROR, {
-							error: sanitizeErrorMessage(
-								deleteError instanceof Error ? deleteError.message : String(deleteError),
-							),
+							error: sanitizeErrorMessage(errorMessage),
 							stack:
 								deleteError instanceof Error
 									? sanitizeErrorMessage(deleteError.stack || "")
 									: undefined,
 							location: "processBatch:deletePointsByMultipleFilePaths",
 							fileCount: uniqueFilePaths.length,
+							errorStatus: errorStatus,
 						})
-						// Re-throw the error with workspace context
+
+						// Re-throw with workspace context
 						throw new Error(
-							`Failed to delete points for ${uniqueFilePaths.length} files. Workspace: ${scanWorkspace}. ${deleteError instanceof Error ? deleteError.message : String(deleteError)}`,
+							`Failed to delete points for ${uniqueFilePaths.length} files. Workspace: ${scanWorkspace}. ${errorMessage}`,
 							{ cause: deleteError },
 						)
 					}
@@ -443,4 +475,55 @@ export class DirectoryScanner implements IDirectoryScanner {
 			}
 		}
 	}
+
+	/**
+	 * Sort files by most recent activity (modified, created, or accessed time)
+	 * @param filePaths Array of file paths to sort
+	 * @returns Promise<string[]> Sorted array with most recently active files first
+	 */
+	private async sortFilesByRecentActivity(filePaths: string[]): Promise<string[]> {
+		interface FileWithTime {
+			path: string
+			mostRecentTime: number
+		}
+
+		const filesWithTimes: FileWithTime[] = []
+
+		// Get file stats for all files with concurrency control
+		const statLimiter = pLimit(50) // Limit concurrent stat operations
+		const statPromises = filePaths.map((filePath) =>
+			statLimiter(async () => {
+				try {
+					const stats = await stat(filePath)
+					
+					// Get the most recent time from modification, creation, and access times
+					const mostRecentTime = Math.max(
+						stats.mtimeMs, // Modified time
+						stats.birthtimeMs, // Creation time
+						stats.atimeMs // Access time
+					)
+
+					return {
+						path: filePath,
+						mostRecentTime
+					}
+				} catch (error) {
+					// If we can't stat the file, give it a very old timestamp so it goes to the end
+					console.warn(`Failed to stat file ${filePath}:`, error)
+					return {
+						path: filePath,
+						mostRecentTime: 0
+					}
+				}
+			})
+		)
+
+		const results = await Promise.all(statPromises)
+		filesWithTimes.push(...results)
+
+		// Sort by most recent time (descending - newest first)
+		filesWithTimes.sort((a, b) => b.mostRecentTime - a.mostRecentTime)
+
+		return filesWithTimes.map(file => file.path)
+	}
 }
diff --git a/src/services/code-index/search-service.ts b/src/services/code-index/search-service.ts
index a56f5cc6..98fcb52f 100644
--- a/src/services/code-index/search-service.ts
+++ b/src/services/code-index/search-service.ts
@@ -55,7 +55,7 @@ export class CodeIndexSearchService {
 			}
 
 			// Perform search
-			const results = await this.vectorStore.search(vector, normalizedPrefix, minScore, maxResults)
+			const results = await this.vectorStore.search(vector, normalizedPrefix, minScore, maxResults, query)
 			return results
 		} catch (error) {
 			console.error("[CodeIndexSearchService] Error during search:", error)
@@ -71,4 +71,48 @@ export class CodeIndexSearchService {
 			throw error // Re-throw the error after setting state
 		}
 	}
+
+	/**
+	 * Gets summary information from the code index.
+	 * @param directoryPrefix Optional directory path to filter results by
+	 * @returns Array of summary strings
+	 * @throws Error if the service is not properly configured or ready
+	 */
+	public async searchSummary(directoryPrefix?: string): Promise<VectorStoreSearchResult[]> {
+		if (!this.configManager.isFeatureEnabled || !this.configManager.isFeatureConfigured) {
+			throw new Error("Code index feature is disabled or not configured.")
+		}
+
+		const currentState = this.stateManager.getCurrentStatus().systemStatus
+		if (currentState !== "Indexed" && currentState !== "Indexing") {
+			// Allow summary during Indexing too
+			throw new Error(`Code index is not ready for summary. Current state: ${currentState}`)
+		}
+
+		try {
+			// Handle directory prefix
+			let normalizedPrefix: string | undefined = undefined
+			if (directoryPrefix) {
+				normalizedPrefix = path.normalize(directoryPrefix)
+			}
+
+			// Perform summary request
+			const results = await this.vectorStore.summary(normalizedPrefix)
+			return results
+		} catch (error) {
+			console.error("[CodeIndexSearchService] Error during summary:", error)
+			this.stateManager.setSystemState("Error", `Summary failed: ${(error as Error).message}`)
+
+			// Capture telemetry for the error
+			TelemetryService.instance.captureEvent(TelemetryEventName.CODE_INDEX_ERROR, {
+				error: (error as Error).message,
+				stack: (error as Error).stack,
+				location: "searchSummary",
+			})
+
+			throw error // Re-throw the error after setting state
+		}
+	}
+
+
 }
diff --git a/src/services/code-index/service-factory.ts b/src/services/code-index/service-factory.ts
index 68b0f5c0..a62959e0 100644
--- a/src/services/code-index/service-factory.ts
+++ b/src/services/code-index/service-factory.ts
@@ -1,15 +1,18 @@
 import * as vscode from "vscode"
 import { OpenAiEmbedder } from "./embedders/openai"
+import { RiddlerEmbedder } from "./embedders/embedding-riddler"
 import { CodeIndexOllamaEmbedder } from "./embedders/ollama"
 import { OpenAICompatibleEmbedder } from "./embedders/openai-compatible"
 import { GeminiEmbedder } from "./embedders/gemini"
 import { MistralEmbedder } from "./embedders/mistral"
 import { EmbedderProvider, getDefaultModelId, getModelDimension } from "../../shared/embeddingModels"
 import { QdrantVectorStore } from "./vector-store/qdrant-client"
-import { codeParser, DirectoryScanner, FileWatcher } from "./processors"
+import { RiddlerVectorStore } from "./vector-store/client-riddler"
+import { codeParser, DirectoryScanner, FileWatcher, riddlerCodeParser } from "./processors"
 import { ICodeParser, IEmbedder, IFileWatcher, IVectorStore } from "./interfaces"
 import { CodeIndexConfigManager } from "./config-manager"
 import { CacheManager } from "./cache-manager"
+import { RooIgnoreController } from "../../core/ignore/RooIgnoreController"
 import { Ignore } from "ignore"
 import { t } from "../../i18n"
 import { TelemetryService } from "@roo-code/telemetry"
@@ -45,12 +48,13 @@ export class CodeIndexServiceFactory {
 			})
 		} else if (provider === "ollama") {
 			if (!config.ollamaOptions?.ollamaBaseUrl) {
-				throw new Error(t("embeddings:serviceFactory.ollamaConfigMissing"))
+				throw new Error(`创建 Codebase-Service 缺少URL配置`)
 			}
-			return new CodeIndexOllamaEmbedder({
-				...config.ollamaOptions,
-				ollamaModelId: config.modelId,
-			})
+			return new RiddlerEmbedder()
+			// return new CodeIndexOllamaEmbedder({
+			// 	...config.ollamaOptions,
+			// 	ollamaModelId: config.modelId,
+			// })
 		} else if (provider === "openai-compatible") {
 			if (!config.openAiCompatibleOptions?.baseUrl || !config.openAiCompatibleOptions?.apiKey) {
 				throw new Error(t("embeddings:serviceFactory.openAiCompatibleConfigMissing"))
@@ -112,6 +116,13 @@ export class CodeIndexServiceFactory {
 		// Use the embedding model ID from config, not the chat model IDs
 		const modelId = config.modelId ?? defaultModel
 
+		if (provider === "ollama") {
+			if (!config.ollamaOptions?.ollamaBaseUrl) {
+				throw new Error(`创建 Codebase-Service 缺少URL配置`)
+			}
+			return new RiddlerVectorStore(this.workspacePath, config.ollamaOptions?.ollamaBaseUrl, 1024, config.qdrantApiKey)
+		}
+
 		let vectorSize: number | undefined
 
 		// First try to get the model-specific dimension from profiles
@@ -160,9 +171,20 @@ export class CodeIndexServiceFactory {
 		embedder: IEmbedder,
 		vectorStore: IVectorStore,
 		cacheManager: CacheManager,
+		codeParser: ICodeParser,
 		ignoreInstance: Ignore,
+		rooIgnoreController?: RooIgnoreController,
 	): IFileWatcher {
-		return new FileWatcher(this.workspacePath, context, cacheManager, embedder, vectorStore, ignoreInstance)
+		return new FileWatcher(
+			this.workspacePath,
+			context,
+			cacheManager,
+			codeParser,
+			embedder,
+			vectorStore,
+			ignoreInstance,
+			rooIgnoreController,
+		)
 	}
 
 	/**
@@ -173,6 +195,7 @@ export class CodeIndexServiceFactory {
 		context: vscode.ExtensionContext,
 		cacheManager: CacheManager,
 		ignoreInstance: Ignore,
+		rooIgnoreController?: RooIgnoreController,
 	): {
 		embedder: IEmbedder
 		vectorStore: IVectorStore
@@ -183,12 +206,22 @@ export class CodeIndexServiceFactory {
 		if (!this.configManager.isFeatureConfigured) {
 			throw new Error(t("embeddings:serviceFactory.codeIndexingNotConfigured"))
 		}
+		const config = this.configManager.getConfig()
+		const provider = config.embedderProvider as EmbedderProvider
 
 		const embedder = this.createEmbedder()
 		const vectorStore = this.createVectorStore()
-		const parser = codeParser
+		const parser = provider !== "ollama" ? codeParser : riddlerCodeParser
 		const scanner = this.createDirectoryScanner(embedder, vectorStore, parser, ignoreInstance)
-		const fileWatcher = this.createFileWatcher(context, embedder, vectorStore, cacheManager, ignoreInstance)
+		const fileWatcher = this.createFileWatcher(
+			context,
+			embedder,
+			vectorStore,
+			cacheManager,
+			parser,
+			ignoreInstance,
+			rooIgnoreController,
+		)
 
 		return {
 			embedder,
diff --git a/src/services/code-index/shared/supported-extensions.ts b/src/services/code-index/shared/supported-extensions.ts
index a5205631..80dd7102 100644
--- a/src/services/code-index/shared/supported-extensions.ts
+++ b/src/services/code-index/shared/supported-extensions.ts
@@ -2,3 +2,33 @@ import { extensions as allExtensions } from "../../tree-sitter"
 
 // Include all extensions including markdown for the scanner
 export const scannerExtensions = allExtensions
+
+/**
+ * Extensions that should always use fallback chunking instead of tree-sitter parsing.
+ * These are typically languages that don't have a proper WASM parser available
+ * or where the parser doesn't work correctly.
+ *
+ * NOTE: Only extensions that are already in the supported extensions list can be added here.
+ * To add support for new file types, they must first be added to the tree-sitter extensions list.
+ *
+ * HOW TO ADD A NEW FALLBACK EXTENSION:
+ * 1. First ensure the extension is in src/services/tree-sitter/index.ts extensions array
+ * 2. Add the extension to the fallbackExtensions array below
+ * 3. The file will automatically use length-based chunking for indexing
+ *
+ * Note: Do NOT remove parser cases from languageParser.ts as they may be used elsewhere
+ */
+export const fallbackExtensions = [
+	".vb", // Visual Basic .NET - no dedicated WASM parser
+	".scala", // Scala - uses fallback chunking instead of Lua query workaround
+	".swift", // Swift - uses fallback chunking due to parser instability
+]
+
+/**
+ * Check if a file extension should use fallback chunking
+ * @param extension File extension (including the dot)
+ * @returns true if the extension should use fallback chunking
+ */
+export function shouldUseFallbackChunking(extension: string): boolean {
+	return fallbackExtensions.includes(extension.toLowerCase())
+}
diff --git a/src/services/code-index/vector-store/qdrant-client.ts b/src/services/code-index/vector-store/qdrant-client.ts
index 5121d65b..1a866dbe 100644
--- a/src/services/code-index/vector-store/qdrant-client.ts
+++ b/src/services/code-index/vector-store/qdrant-client.ts
@@ -7,6 +7,8 @@ import { Payload, VectorStoreSearchResult } from "../interfaces"
 import { DEFAULT_MAX_SEARCH_RESULTS, DEFAULT_SEARCH_MIN_SCORE } from "../constants"
 import { t } from "../../../i18n"
 
+import * as vscode from "vscode"
+
 /**
  * Qdrant implementation of the vector store interface
  */
@@ -76,7 +78,7 @@ export class QdrantVectorStore implements IVectorStore {
 		}
 
 		// Generate collection name from workspace path
-		const hash = createHash("sha256").update(workspacePath).digest("hex")
+		const hash = createHash("sha256").update(`${vscode.env.machineId}@${workspacePath}`).digest("hex")
 		this.vectorSize = vectorSize
 		this.collectionName = `ws-${hash.substring(0, 16)}`
 	}
@@ -370,18 +372,32 @@ export class QdrantVectorStore implements IVectorStore {
 		directoryPrefix?: string,
 		minScore?: number,
 		maxResults?: number,
+		query?:string,
 	): Promise<VectorStoreSearchResult[]> {
 		try {
 			let filter = undefined
 
 			if (directoryPrefix) {
-				const segments = directoryPrefix.split(path.sep).filter(Boolean)
-
-				filter = {
-					must: segments.map((segment, index) => ({
-						key: `pathSegments.${index}`,
-						match: { value: segment },
-					})),
+				// Check if the path represents current directory
+				const normalizedPrefix = path.posix.normalize(directoryPrefix.replace(/\\/g, "/"))
+				// Note: path.posix.normalize("") returns ".", and normalize("./") returns "./"
+				if (normalizedPrefix === "." || normalizedPrefix === "./") {
+					// Don't create a filter - search entire workspace
+					filter = undefined
+				} else {
+					// Remove leading "./" from paths like "./src" to normalize them
+					const cleanedPrefix = path.posix.normalize(
+						normalizedPrefix.startsWith("./") ? normalizedPrefix.slice(2) : normalizedPrefix,
+					)
+					const segments = cleanedPrefix.split("/").filter(Boolean)
+					if (segments.length > 0) {
+						filter = {
+							must: segments.map((segment, index) => ({
+								key: `pathSegments.${index}`,
+								match: { value: segment },
+							})),
+						}
+					}
 				}
 			}
 
@@ -423,27 +439,62 @@ export class QdrantVectorStore implements IVectorStore {
 		}
 
 		try {
+			// First check if the collection exists
+			const collectionExists = await this.collectionExists()
+			if (!collectionExists) {
+				console.warn(
+					`[QdrantVectorStore] Skipping deletion - collection "${this.collectionName}" does not exist`,
+				)
+				return
+			}
+
 			const workspaceRoot = getWorkspacePath()
-			const normalizedPaths = filePaths.map((filePath) => {
-				const absolutePath = path.resolve(workspaceRoot, filePath)
-				return path.normalize(absolutePath)
+
+			// Build filters using pathSegments to match the indexed fields
+			const filters = filePaths.map((filePath) => {
+				// IMPORTANT: Use the relative path to match what's stored in upsertPoints
+				// upsertPoints stores the relative filePath, not the absolute path
+				const relativePath = path.isAbsolute(filePath) ? path.relative(workspaceRoot, filePath) : filePath
+
+				// Normalize the relative path
+				const normalizedRelativePath = path.normalize(relativePath)
+
+				// Split the path into segments like we do in upsertPoints
+				const segments = normalizedRelativePath.split(path.sep).filter(Boolean)
+
+				// Create a filter that matches all segments of the path
+				// This ensures we only delete points that match the exact file path
+				const mustConditions = segments.map((segment, index) => ({
+					key: `pathSegments.${index}`,
+					match: { value: segment },
+				}))
+
+				return { must: mustConditions }
 			})
 
-			const filter = {
-				should: normalizedPaths.map((normalizedPath) => ({
-					key: "filePath",
-					match: {
-						value: normalizedPath,
-					},
-				})),
-			}
+			// Use 'should' to match any of the file paths (OR condition)
+			const filter = filters.length === 1 ? filters[0] : { should: filters }
 
 			await this.client.delete(this.collectionName, {
 				filter,
 				wait: true,
 			})
-		} catch (error) {
-			console.error("Failed to delete points by file paths:", error)
+		} catch (error: any) {
+			// Extract more detailed error information
+			const errorMessage = error?.message || String(error)
+			const errorStatus = error?.status || error?.response?.status || error?.statusCode
+			const errorDetails = error?.response?.data || error?.data || ""
+
+			console.error(`[QdrantVectorStore] Failed to delete points by file paths:`, {
+				error: errorMessage,
+				status: errorStatus,
+				details: errorDetails,
+				collection: this.collectionName,
+				fileCount: filePaths.length,
+				// Include first few file paths for debugging (avoid logging too many)
+				samplePaths: filePaths.slice(0, 3),
+			})
+
 			throw error
 		}
 	}
@@ -463,6 +514,12 @@ export class QdrantVectorStore implements IVectorStore {
 		}
 	}
 
+	async summary(
+		directoryPrefix?: string,
+	): Promise<VectorStoreSearchResult[]> {
+		return []
+	}
+
 	/**
 	 * Clears all points from the collection
 	 */
diff --git a/src/services/mcp/McpHub.ts b/src/services/mcp/McpHub.ts
index 10a74712..b4562d4e 100644
--- a/src/services/mcp/McpHub.ts
+++ b/src/services/mcp/McpHub.ts
@@ -46,6 +46,8 @@ const BaseConfigSchema = z.object({
 	alwaysAllow: z.array(z.string()).default([]),
 	watchPaths: z.array(z.string()).optional(), // paths to watch for changes and restart server
 	disabledTools: z.array(z.string()).default([]),
+	enabledModes: z.array(z.string()).default([]),
+	disabledModes: z.array(z.string()).default([]),
 })
 
 // Custom error messages for better user feedback
diff --git a/src/services/ripgrep/index.ts b/src/services/ripgrep/index.ts
index c6942219..ff4fd2ae 100644
--- a/src/services/ripgrep/index.ts
+++ b/src/services/ripgrep/index.ts
@@ -6,6 +6,9 @@ import * as vscode from "vscode"
 
 import { RooIgnoreController } from "../../core/ignore/RooIgnoreController"
 import { fileExistsAtPath } from "../../utils/fs"
+
+// Output mode enum
+export type OutputMode = "content" | "files_with_matches"
 /*
 This file provides functionality to perform regex searches on files using ripgrep.
 Inspired by: https://github.com/DiscreteTom/vscode-ripgrep-utils
@@ -28,6 +31,8 @@ The search results include:
 
 Usage example:
 const results = await regexSearchFiles('/path/to/cwd', '/path/to/search', 'TODO:', '*.ts');
+// Or with files_with_matches mode (uses -l flag, returns plain text file paths):
+const filesOnly = await regexSearchFiles('/path/to/cwd', '/path/to/search', 'TODO:', '*.ts', undefined, 'files_with_matches');
 
 rel/path/to/app.ts
 │----
@@ -96,7 +101,7 @@ export async function getBinPath(vscodeAppRoot: string): Promise<string | undefi
 	)
 }
 
-async function execRipgrep(bin: string, args: string[]): Promise<string> {
+async function execRipgrep(bin: string, args: string[], mode:string): Promise<string> {
 	return new Promise((resolve, reject) => {
 		const rgProcess = childProcess.spawn(bin, args)
 		// cross-platform alternative to head, which is ripgrep author's recommendation for limiting output.
@@ -107,7 +112,7 @@ async function execRipgrep(bin: string, args: string[]): Promise<string> {
 
 		let output = ""
 		let lineCount = 0
-		const maxLines = MAX_RESULTS * 5 // limiting ripgrep output with max lines since there's no other way to limit results. it's okay that we're outputting as json, since we're parsing it line by line and ignore anything that's not part of a match. This assumes each result is at most 5 lines.
+		const maxLines = MAX_RESULTS * (mode === "content" ? 5 : 1) // limiting ripgrep output with max lines since there's no other way to limit results. it's okay that we're outputting as json, since we're parsing it line by line and ignore anything that's not part of a match. This assumes each result is at most 5 lines.
 
 		rl.on("line", (line) => {
 			if (lineCount < maxLines) {
@@ -142,6 +147,7 @@ export async function regexSearchFiles(
 	regex: string,
 	filePattern?: string,
 	rooIgnoreController?: RooIgnoreController,
+	outputMode: OutputMode = "content",
 ): Promise<string> {
 	const vscodeAppRoot = vscode.env.appRoot
 	const rgPath = await getBinPath(vscodeAppRoot)
@@ -150,65 +156,99 @@ export async function regexSearchFiles(
 		throw new Error("Could not find ripgrep binary")
 	}
 
-	const args = ["--json", "-e", regex, "--glob", filePattern || "*", "--context", "1", directoryPath]
+	// Adjust args based on output mode
+	const args = outputMode === "files_with_matches"
+		? ["-l", "-e", regex, "--glob", filePattern || "*", directoryPath]
+		: ["--json", "-e", regex, "--glob", filePattern || "*", "--context", "1", directoryPath]
 
 	let output: string
 	try {
-		output = await execRipgrep(rgPath, args)
+		output = await execRipgrep(rgPath, args, outputMode)
 	} catch (error) {
 		console.error("Error executing ripgrep:", error)
 		return "No results found"
 	}
 
+	try {
+		if (((outputMode === "files_with_matches" && !output) || (outputMode === "content" && output.split("\n").length < 3)) && filePattern?.includes(",")) {
+			let outs:any[] = []
+			const _filePattern = filePattern?.split(",")
+			_filePattern.forEach((pattern) => {
+				const args = outputMode === "files_with_matches"
+					? ["-l", "-e", regex, "--glob", pattern.trim(), directoryPath]
+					: ["--json", "-e", regex, "--glob", pattern.trim(), "--context", "1", directoryPath]
+				outs.push(execRipgrep(rgPath, args, outputMode))
+			})
+			output = (await Promise.all(outs)).join("\n")
+		}
+	} catch (error) {
+		output = ""
+	}
+
 	const results: SearchFileResult[] = []
 	let currentFile: SearchFileResult | null = null
 
-	output.split("\n").forEach((line) => {
-		if (line) {
-			try {
-				const parsed = JSON.parse(line)
-				if (parsed.type === "begin") {
-					currentFile = {
-						file: parsed.data.path.text.toString(),
-						searchResults: [],
-					}
-				} else if (parsed.type === "end") {
-					// Reset the current result when a new file is encountered
-					results.push(currentFile as SearchFileResult)
-					currentFile = null
-				} else if ((parsed.type === "match" || parsed.type === "context") && currentFile) {
-					const line = {
-						line: parsed.data.line_number,
-						text: truncateLine(parsed.data.lines.text),
-						isMatch: parsed.type === "match",
-						...(parsed.type === "match" && { column: parsed.data.absolute_offset }),
-					}
-
-					const lastResult = currentFile.searchResults[currentFile.searchResults.length - 1]
-					if (lastResult?.lines.length > 0) {
-						const lastLine = lastResult.lines[lastResult.lines.length - 1]
+	// Handle files_with_matches mode differently - ripgrep with -l outputs plain text file paths
+	if (outputMode === "files_with_matches") {
+		// Parse plain text output (one file path per line)
+		output.split("\n").forEach((line) => {
+			const trimmedLine = line.trim()
+			if (trimmedLine) {
+				results.push({
+					file: trimmedLine,
+					searchResults: [], // Empty for files_with_matches mode
+				})
+			}
+		})
+	} else {
+		// Original content mode logic - parse JSON output
+		output.split("\n").forEach((line) => {
+			if (line) {
+				try {
+					const parsed = JSON.parse(line)
+					if (parsed.type === "begin") {
+						currentFile = {
+							file: parsed.data.path.text.toString(),
+							searchResults: [],
+						}
+					} else if (parsed.type === "end") {
+						// Reset the current result when a new file is encountered
+						results.push(currentFile as SearchFileResult)
+						currentFile = null
+					} else if ((parsed.type === "match" || parsed.type === "context") && currentFile) {
+						const line = {
+							line: parsed.data.line_number,
+							text: truncateLine(parsed.data.lines.text),
+							isMatch: parsed.type === "match",
+							...(parsed.type === "match" && { column: parsed.data.absolute_offset }),
+						}
 
-						// If this line is contiguous with the last result, add to it
-						if (parsed.data.line_number <= lastLine.line + 1) {
-							lastResult.lines.push(line)
+						const lastResult = currentFile.searchResults[currentFile.searchResults.length - 1]
+						if (lastResult?.lines.length > 0) {
+							const lastLine = lastResult.lines[lastResult.lines.length - 1]
+
+							// If this line is contiguous with the last result, add to it
+							if (parsed.data.line_number <= lastLine.line + 1) {
+								lastResult.lines.push(line)
+							} else {
+								// Otherwise create a new result
+								currentFile.searchResults.push({
+									lines: [line],
+								})
+							}
 						} else {
-							// Otherwise create a new result
+							// First line in file
 							currentFile.searchResults.push({
 								lines: [line],
 							})
 						}
-					} else {
-						// First line in file
-						currentFile.searchResults.push({
-							lines: [line],
-						})
 					}
+				} catch (error) {
+					console.error("Error parsing ripgrep output:", error)
 				}
-			} catch (error) {
-				console.error("Error parsing ripgrep output:", error)
 			}
-		}
-	})
+		})
+	}
 
 	// console.log(results)
 
@@ -217,18 +257,39 @@ export async function regexSearchFiles(
 		? results.filter((result) => rooIgnoreController.validateAccess(result.file))
 		: results
 
-	return formatResults(filteredResults, cwd)
+	return formatResults(filteredResults, cwd, outputMode)
 }
 
-function formatResults(fileResults: SearchFileResult[], cwd: string): string {
+function formatResults(fileResults: SearchFileResult[], cwd: string, outputMode: OutputMode = "content"): string {
+	// Handle files_with_matches mode
+	if (outputMode === "files_with_matches") {
+		let output = ""
+		const totalFiles = fileResults.length
+		
+		if (totalFiles >= MAX_RESULTS) {
+			output += `Showing first ${MAX_RESULTS} of ${MAX_RESULTS}+ files with matches. **You should use a more specific search, or switch to multiple SMALLER DIRECTORY SCOPES to searching separately. Do not give up on the search, as it may lead to the loss of relevant contextual information.**\n\n`
+		} else {
+			output += `Found ${totalFiles === 1 ? "1 file" : `${totalFiles.toLocaleString()} files`} with matches${totalFiles === 0 ? ". You should try switching the search scope or changing the search content." : ''}.\n\n`
+		}
+
+		// List files only
+		fileResults.slice(0, MAX_RESULTS).forEach((file) => {
+			const relativeFilePath = path.relative(cwd, file.file)
+			output += `${relativeFilePath.toPosix()}\n`
+		})
+
+		return output.trim()
+	}
+
+	// Original content mode logic
 	const groupedResults: { [key: string]: SearchResult[] } = {}
 
 	let totalResults = fileResults.reduce((sum, file) => sum + file.searchResults.length, 0)
 	let output = ""
 	if (totalResults >= MAX_RESULTS) {
-		output += `Showing first ${MAX_RESULTS} of ${MAX_RESULTS}+ results. Use a more specific search if necessary.\n\n`
+		output += `Showing first ${MAX_RESULTS} of ${MAX_RESULTS}+ results. **You should use a more specific search, or switch to multiple SMALLER DIRECTORY SCOPES to searching separately. Do not give up on the search, as it may lead to the loss of relevant contextual information.**\n\n`
 	} else {
-		output += `Found ${totalResults === 1 ? "1 result" : `${totalResults.toLocaleString()} results`}.\n\n`
+		output += `Found ${totalResults === 1 ? "1 result" : `${totalResults.toLocaleString()} results${totalResults === 0 ? ". You should try switching the search scope or changing the search content." : ''}`}.\n\n`
 	}
 
 	// Group results by file name
diff --git a/src/services/search/file-search.ts b/src/services/search/file-search.ts
index a25dd406..ba70bda5 100644
--- a/src/services/search/file-search.ts
+++ b/src/services/search/file-search.ts
@@ -155,7 +155,64 @@ export async function searchWorkspaceFiles(
 			}),
 		)
 
-		return verifiedResults
+		// return verifiedResults
+		let inc: typeof allItems = []
+		const _query = query.replace(/\\/g, '/')
+		if (_query.includes("/")) {
+			inc = allItems
+				.filter((item) => {
+					const itemAbsolutePath = path.resolve(workspacePath, item.path).replace(/\\/g, '/')
+					if (!itemAbsolutePath.includes(_query)) {
+						return false
+					}
+					// const afterQuery = itemAbsolutePath.split(abs_queryPath).pop() || ""
+					// const slashCount = (afterQuery.match(/\//g) || []).length
+					// if (slashCount > 1 && !afterQuery.endsWith('/')) {
+					// 	return false
+					// }
+					return true
+				})
+				.map((item) => {
+					const fullPath = path.join(workspacePath, item.path)
+					const isDirectory = fs.lstatSync(fullPath).isDirectory()
+					return {
+						...item,
+						path: item.path.toPosix(),
+						type: isDirectory ? ("folder" as const) : ("file" as const),
+					}
+				})
+		}
+		
+		// const abs_queryPath = path.resolve(workspacePath, query).replace(/\\/g, '/')
+		// let inc: typeof allItems = []
+		// if (fs.existsSync(abs_queryPath)) {
+		// 	inc = allItems
+		// 		.filter((item) => {
+		// 			const itemAbsolutePath = path.resolve(workspacePath, item.path).replace(/\\/g, '/')
+		// 			if (!itemAbsolutePath.includes(abs_queryPath)) {
+		// 				return false
+		// 			}
+		// 			const afterQuery = itemAbsolutePath.split(abs_queryPath).pop() || ""
+		// 			const slashCount = (afterQuery.match(/\//g) || []).length
+		// 			if (slashCount > 1 && !afterQuery.endsWith('/')) {
+		// 				return false
+		// 			}
+		// 			return true
+		// 		})
+		// 		.map((item) => {
+		// 			const fullPath = path.join(workspacePath, item.path)
+		// 			const isDirectory = fs.lstatSync(fullPath).isDirectory()
+		// 			return {
+		// 				...item,
+		// 				path: item.path.toPosix(),
+		// 				type: isDirectory ? ("folder" as const) : ("file" as const),
+		// 			}
+		// 		})
+		// }
+
+		return [...inc,...verifiedResults,].filter((item) => {
+			return item.type !== "folder"
+		})
 	} catch (error) {
 		console.error("Error in searchWorkspaceFiles:", error)
 		return []
diff --git a/src/shared/ExtensionMessage.ts b/src/shared/ExtensionMessage.ts
index 1e562bb9..222a8594 100644
--- a/src/shared/ExtensionMessage.ts
+++ b/src/shared/ExtensionMessage.ts
@@ -69,6 +69,7 @@ export interface ExtensionMessage {
 		| "messageUpdated"
 		| "mcpServers"
 		| "enhancedPrompt"
+		| "savedMemory"
 		| "commitSearchResults"
 		| "listApiConfig"
 		| "routerModels"
@@ -103,6 +104,7 @@ export interface ExtensionMessage {
 		| "setHistoryPreviewCollapsed"
 		| "commandExecutionStatus"
 		| "mcpExecutionStatus"
+		| "toolExecutionStatus"
 		| "vsCodeSetting"
 		| "authenticatedUser"
 		| "condenseTaskContextResponse"
@@ -335,6 +337,8 @@ export interface ClineSayTool {
 		| "listFilesRecursive"
 		| "listCodeDefinitionNames"
 		| "searchFiles"
+		| "webSearch"
+		| "urlFetch"
 		| "switchMode"
 		| "newTask"
 		| "finishTask"
@@ -376,6 +380,18 @@ export interface ClineSayTool {
 		}>
 	}>
 	question?: string
+	// Tool execution properties
+	url?: string
+	toolName?: string
+	toolDisplayName?: string
+	parameters?: Array<{
+		name: string
+		value: string
+		label?: string
+	}>
+	response?: string
+	status?: "executing" | "completed" | "error"
+	error?: string
 }
 
 // Must keep in sync with system prompt.
@@ -415,6 +431,16 @@ export interface ClineAskUseMcpServer {
 	response?: string
 }
 
+export interface ClineAskWebSearch {
+	query: string
+	response?: string
+}
+
+export interface ClineAskUrlFetch {
+	url: string
+	response?: string
+}
+
 export interface ClineApiReqInfo {
 	request?: string
 	tokensIn?: number
@@ -425,6 +451,8 @@ export interface ClineApiReqInfo {
 	cancelReason?: ClineApiReqCancelReason
 	streamingFailedMessage?: string
 	apiProtocol?: "anthropic" | "openai"
+	tps?: number
+	latency?: number // optional latency in milliseconds
 }
 
 export type ClineApiReqCancelReason = "streaming_failed" | "user_cancelled"
diff --git a/src/shared/ProfileValidator.ts b/src/shared/ProfileValidator.ts
index 9cfba84a..58e89b9d 100644
--- a/src/shared/ProfileValidator.ts
+++ b/src/shared/ProfileValidator.ts
@@ -62,6 +62,8 @@ export class ProfileValidator {
 			case "bedrock":
 			case "vertex":
 			case "gemini":
+			case "doubao":	
+			case "modelscope":
 			case "mistral":
 			case "deepseek":
 			case "xai":
diff --git a/src/shared/WebviewMessage.ts b/src/shared/WebviewMessage.ts
index 0b0cc068..9e1973b6 100644
--- a/src/shared/WebviewMessage.ts
+++ b/src/shared/WebviewMessage.ts
@@ -108,6 +108,9 @@ export interface WebviewMessage {
 		| "updateMcpTimeout"
 		| "fuzzyMatchThreshold"
 		| "writeDelayMs"
+		| "useTerminalCommand"
+		| "saveMemory"
+		| "savedMemory"
 		| "diagnosticsEnabled"
 		| "enhancePrompt"
 		| "enhancedPrompt"
diff --git a/src/shared/combineCommandSequences.ts b/src/shared/combineCommandSequences.ts
index 2f655feb..346485eb 100644
--- a/src/shared/combineCommandSequences.ts
+++ b/src/shared/combineCommandSequences.ts
@@ -6,10 +6,12 @@ export const COMMAND_OUTPUT_STRING = "Output:"
 /**
  * Combines sequences of command and command_output messages in an array of ClineMessages.
  * Also combines sequences of use_mcp_server and mcp_server_response messages.
+ * Also handles web_search, url_fetch and other tool execution status messages.
  *
  * This function processes an array of ClineMessages objects, looking for sequences
  * where a 'command' message is followed by one or more 'command_output' messages,
- * or where a 'use_mcp_server' message is followed by one or more 'mcp_server_response' messages.
+ * or where a 'use_mcp_server' message is followed by one or more 'mcp_server_response' messages,
+ * or where tool execution messages (web_search, url_fetch) need to preserve their response data.
  * When such a sequence is found, it combines them into a single message, merging
  * their text contents.
  *
@@ -33,9 +35,9 @@ export function combineCommandSequences(messages: ClineMessage[]): ClineMessage[
 	for (let i = 0; i < messages.length; i++) {
 		const msg = messages[i]
 
-		// Handle MCP server requests
-		if (msg.type === "ask" && msg.ask === "use_mcp_server") {
-			// Look ahead for MCP responses
+		// Handle MCP server requests and other tool requests (web_search, url_fetch)
+		if (msg.type === "ask" && (msg.ask === "use_mcp_server" || msg.ask === "web_search" || msg.ask === "url_fetch")) {
+			// Look ahead for tool responses
 			let responses: string[] = []
 			let j = i + 1
 
@@ -44,8 +46,8 @@ export function combineCommandSequences(messages: ClineMessage[]): ClineMessage[
 					responses.push(messages[j].text || "")
 					processedIndices.add(j)
 					j++
-				} else if (messages[j].type === "ask" && messages[j].ask === "use_mcp_server") {
-					// Stop if we encounter another MCP request
+				} else if (messages[j].type === "ask" && (messages[j].ask === "use_mcp_server" || messages[j].ask === "web_search" || messages[j].ask === "url_fetch")) {
+					// Stop if we encounter another tool request
 					break
 				} else {
 					j++
diff --git a/src/shared/experiments.ts b/src/shared/experiments.ts
index 548b55f6..245e44d9 100644
--- a/src/shared/experiments.ts
+++ b/src/shared/experiments.ts
@@ -4,6 +4,7 @@ export const EXPERIMENT_IDS = {
 	MULTI_FILE_APPLY_DIFF: "multiFileApplyDiff",
 	POWER_STEERING: "powerSteering",
 	PREVENT_FOCUS_DISRUPTION: "preventFocusDisruption",
+	ALLOWED_MULTI_CALL: "allowedMultiCall",
 } as const satisfies Record<string, ExperimentId>
 
 type _AssertExperimentIds = AssertEqual<Equals<ExperimentId, Values<typeof EXPERIMENT_IDS>>>
@@ -18,6 +19,7 @@ export const experimentConfigsMap: Record<ExperimentKey, ExperimentConfig> = {
 	MULTI_FILE_APPLY_DIFF: { enabled: false },
 	POWER_STEERING: { enabled: false },
 	PREVENT_FOCUS_DISRUPTION: { enabled: false },
+	ALLOWED_MULTI_CALL: { enabled: false },
 }
 
 export const experimentDefault = Object.fromEntries(
diff --git a/src/shared/getApiMetrics.ts b/src/shared/getApiMetrics.ts
index dcd9ae9e..1d3b4cab 100644
--- a/src/shared/getApiMetrics.ts
+++ b/src/shared/getApiMetrics.ts
@@ -63,6 +63,10 @@ export function getApiMetrics(messages: ClineMessage[]) {
 			}
 		} else if (message.type === "say" && message.say === "condense_context") {
 			result.totalCost += message.contextCondense?.cost ?? 0
+		} else if (message.type === "say" && message.say === "save_memory") {
+			result.totalCost += message.contextCondense?.cost ?? 0
+		} else if (message.type === "say" && message.say === "cost_tracking") {
+			result.totalCost += message.contextCondense?.cost ?? 0
 		}
 	})
 
@@ -88,6 +92,10 @@ export function getApiMetrics(messages: ClineMessage[]) {
 			}
 		} else if (message.type === "say" && message.say === "condense_context") {
 			result.contextTokens = message.contextCondense?.newContextTokens ?? 0
+		} else if (message.type === "say" && message.say === "save_memory") {
+			continue
+		} else if (message.type === "say" && message.say === "cost_tracking") {
+			continue
 		}
 		if (result.contextTokens) {
 			break
diff --git a/src/shared/support-prompt.ts b/src/shared/support-prompt.ts
index 51f4310f..58364c57 100644
--- a/src/shared/support-prompt.ts
+++ b/src/shared/support-prompt.ts
@@ -49,7 +49,7 @@ const supportPromptConfigs: Record<SupportPromptType, SupportPromptConfig> = {
 	ENHANCE: {
 		template: `Generate an enhanced version of this prompt (reply with only the enhanced prompt - no conversation, explanations, lead-in, bullet points, placeholders, or surrounding quotes):
 
-\${userInput}`,
+\${userInput}\n`,
 	},
 	CONDENSE: {
 		template: `Your task is to create a detailed summary of the conversation so far, paying close attention to the user's explicit requests and your previous actions.
@@ -88,7 +88,7 @@ Example summary structure:
   - [Task 2 details & next steps]
   - [...]
 
-Output only the summary of the conversation so far, without any additional commentary or explanation.`,
+Output only the summary of the conversation so far, without any additional commentary or explanation.\n`,
 	},
 	EXPLAIN: {
 		template: `Explain the following code from file path \${filePath}:\${startLine}-\${endLine}
@@ -101,7 +101,7 @@ Output only the summary of the conversation so far, without any additional comme
 Please provide a clear and concise explanation of what this code does, including:
 1. The purpose and functionality
 2. Key components and their interactions
-3. Important patterns or techniques used`,
+3. Important patterns or techniques used\n`,
 	},
 	FIX: {
 		template: `Fix any issues in the following code from file path \${filePath}:\${startLine}-\${endLine}
@@ -116,7 +116,7 @@ Please:
 1. Address all detected problems listed above (if any)
 2. Identify any other potential bugs or issues
 3. Provide corrected code
-4. Explain what was fixed and why`,
+4. Explain what was fixed and why\n`,
 	},
 	IMPROVE: {
 		template: `Improve the following code from file path \${filePath}:\${startLine}-\${endLine}
@@ -132,20 +132,20 @@ Please suggest improvements for:
 3. Best practices and patterns
 4. Error handling and edge cases
 
-Provide the improved code along with explanations for each enhancement.`,
+Provide the improved code along with explanations for each enhancement.\n`,
 	},
 	ADD_TO_CONTEXT: {
 		template: `\${filePath}:\${startLine}-\${endLine}
 \`\`\`
 \${selectedText}
-\`\`\``,
+\`\`\`\n`,
 	},
 	TERMINAL_ADD_TO_CONTEXT: {
 		template: `\${userInput}
 Terminal output:
 \`\`\`
 \${terminalContent}
-\`\`\``,
+\`\`\`\n`,
 	},
 	TERMINAL_FIX: {
 		template: `\${userInput}
@@ -157,7 +157,7 @@ Fix this terminal command:
 Please:
 1. Identify any issues in the command
 2. Provide the corrected command
-3. Explain what was fixed and why`,
+3. Explain what was fixed and why\n`,
 	},
 	TERMINAL_EXPLAIN: {
 		template: `\${userInput}
@@ -169,10 +169,10 @@ Explain this terminal command:
 Please provide:
 1. What the command does
 2. Explanation of each part/flag
-3. Expected output and behavior`,
+3. Expected output and behavior\n`,
 	},
 	NEW_TASK: {
-		template: `\${userInput}`,
+		template: `\${userInput}\n`,
 	},
 } as const
 
diff --git a/src/shared/tools.ts b/src/shared/tools.ts
index 67972243..4de351fd 100644
--- a/src/shared/tools.ts
+++ b/src/shared/tools.ts
@@ -65,6 +65,7 @@ export const toolParamNames = [
 	"query",
 	"args",
 	"todos",
+	"output_mode",
 ] as const
 
 export type ToolParamName = (typeof toolParamNames)[number]
@@ -110,7 +111,7 @@ export interface CodebaseSearchToolUse extends ToolUse {
 
 export interface SearchFilesToolUse extends ToolUse {
 	name: "search_files"
-	params: Partial<Pick<Record<ToolParamName, string>, "path" | "regex" | "file_pattern">>
+	params: Partial<Pick<Record<ToolParamName, string>, "path" | "regex" | "file_pattern" | "output_mode">>
 }
 
 export interface ListFilesToolUse extends ToolUse {
@@ -164,6 +165,16 @@ export interface SearchAndReplaceToolUse extends ToolUse {
 		Partial<Pick<Record<ToolParamName, string>, "use_regex" | "ignore_case" | "start_line" | "end_line">>
 }
 
+export interface WebSearchToolUse extends ToolUse {
+	name: "web_search"
+	params: Partial<Pick<Record<ToolParamName, string>, "query">>
+}
+
+export interface UrlFetchToolUse extends ToolUse {
+	name: "url_fetch"
+	params: Partial<Pick<Record<ToolParamName, string>, "url">>
+}
+
 // Define tool group configuration
 export type ToolGroupConfig = {
 	tools: readonly string[]
@@ -190,6 +201,8 @@ export const TOOL_DISPLAY_NAMES: Record<ToolName, string> = {
 	search_and_replace: "search and replace",
 	codebase_search: "codebase search",
 	update_todo_list: "update todo list",
+	web_search: "web search",
+	url_fetch: "fetch url content",
 } as const
 
 // Define available tool groups.
@@ -202,6 +215,8 @@ export const TOOL_GROUPS: Record<ToolGroup, ToolGroupConfig> = {
 			"list_files",
 			"list_code_definition_names",
 			"codebase_search",
+			"web_search",
+			"url_fetch",
 		],
 	},
 	edit: {
diff --git a/webview-ui/src/components/chat/ChatRow.tsx b/webview-ui/src/components/chat/ChatRow.tsx
index 4fa921f4..0d3143d1 100644
--- a/webview-ui/src/components/chat/ChatRow.tsx
+++ b/webview-ui/src/components/chat/ChatRow.tsx
@@ -1,6 +1,7 @@
 import React, { memo, useCallback, useEffect, useMemo, useRef, useState } from "react"
 import { appendImages } from "@src/utils/imageUtils"
 import { McpExecution } from "./McpExecution"
+import { ToolExecution } from "./ToolExecution"
 import { useSize } from "react-use"
 import { useTranslation, Trans } from "react-i18next"
 import deepEqual from "fast-deep-equal"
@@ -45,6 +46,7 @@ import { CommandExecution } from "./CommandExecution"
 import { CommandExecutionError } from "./CommandExecutionError"
 import { AutoApprovedRequestLimitWarning } from "./AutoApprovedRequestLimitWarning"
 import { CondenseContextErrorRow, CondensingContextRow, ContextCondenseRow } from "./ContextCondenseRow"
+import { SaveMemoryErrorRow, SavingMemoryRow, SaveMemoryRow } from "./saveMemoryRow-rid"
 import CodebaseSearchResultsDisplay from "./CodebaseSearchResultsDisplay"
 
 interface ChatRowProps {
@@ -123,7 +125,7 @@ export const ChatRowContent = ({
 	const [editMode, setEditMode] = useState<Mode>(mode || "code")
 	const [editImages, setEditImages] = useState<string[]>([])
 	const { copyWithFeedback } = useCopyToClipboard()
-
+	
 	// Handle message events for image selection during edit mode
 	useEffect(() => {
 		const handleMessage = (event: MessageEvent) => {
@@ -177,15 +179,23 @@ export const ChatRowContent = ({
 		vscode.postMessage({ type: "selectImages", context: "edit", messageTs: message.ts })
 	}, [message.ts])
 
-	const [cost, apiReqCancelReason, apiReqStreamingFailedMessage] = useMemo(() => {
+	const [cost, apiReqCancelReason, apiReqStreamingFailedMessage, tps, latency] = useMemo(() => {
 		if (message.text !== null && message.text !== undefined && message.say === "api_req_started") {
 			const info = safeJsonParse<ClineApiReqInfo>(message.text)
-			return [info?.cost, info?.cancelReason, info?.streamingFailedMessage]
+			return [info?.cost, info?.cancelReason, info?.streamingFailedMessage, info?.tps, info?.latency]
 		}
 
-		return [undefined, undefined, undefined]
+		return [undefined, undefined, undefined, undefined, undefined]
 	}, [message.text, message.say])
 
+
+
+	console.log(`lastModifiedMessage.ask = ${lastModifiedMessage?.ask || ''}, 
+		Message.ask = ${message.ask}
+		tps = ${tps}
+		cost = ${cost}`)
+	
+
 	// When resuming task, last wont be api_req_failed but a resume_task
 	// message, so api_req_started will show loading spinner. That's why we just
 	// remove the last api_req_started that failed without streaming anything.
@@ -259,6 +269,20 @@ export const ChatRowContent = ({
 						style={{ color: successColor, marginBottom: "-1.5px" }}></span>,
 					<span style={{ color: successColor, fontWeight: "bold" }}>{t("chat:taskCompleted")}</span>,
 				]
+			case "user_feedback":
+				return [
+					<span
+						className="codicon codicon-account"
+						style={{ color: "var(--vscode-charts-blue)", marginBottom: "-1.5px" }}></span>,
+					<span style={{ color: "var(--vscode-charts-blue)", fontWeight: "bold" }}>{"用户反馈"}</span>,
+				]
+			case "save_memory_tag":
+				return [
+					<span
+						className="codicon codicon-save"
+						style={{ color: "#00a3af44", marginBottom: "-1.5px" }}></span>,
+					<span style={{  color: "#00a3af77", fontWeight: "bold" }}>{"记忆说明"}</span>,
+				]
 			case "api_req_retry_delayed":
 				return []
 			case "api_req_started":
@@ -317,6 +341,32 @@ export const ChatRowContent = ({
 					/>,
 					<span style={{ color: normalColor, fontWeight: "bold" }}>{t("chat:questions.hasQuestion")}</span>,
 				]
+			case "web_search":
+				return [
+					isMcpServerResponding ? (
+						<ProgressIndicator />
+					) : (
+						<span
+							className="codicon codicon-search"
+							style={{ color: normalColor, marginBottom: "-1.5px" }}></span>
+					),
+					<span style={{ color: normalColor, fontWeight: "bold" }}>
+						{isMcpServerResponding ? "网络搜索" : "网络搜索完成"}
+					</span>,
+				]
+			case "url_fetch":
+				return [
+					isMcpServerResponding ? (
+						<ProgressIndicator />
+					) : (
+						<span
+							className="codicon codicon-globe"
+							style={{ color: normalColor, marginBottom: "-1.5px" }}></span>
+					),
+					<span style={{ color: normalColor, fontWeight: "bold" }}>
+						{isMcpServerResponding ? "URL内容分析" : "URL内容分析完成"}
+					</span>,
+				]
 			default:
 				return [null, null]
 		}
@@ -972,6 +1022,8 @@ export const ChatRowContent = ({
 									style={{
 										padding: "12px 16px",
 										backgroundColor: "var(--vscode-editor-background)",
+										maxHeight: "360px",
+										overflowY: "auto",
 									}}>
 									<MarkdownBlock markdown={message.text} />
 								</div>
@@ -1013,6 +1065,14 @@ export const ChatRowContent = ({
 										style={{ opacity: cost !== null && cost !== undefined && cost > 0 ? 1 : 0 }}>
 										${Number(cost || 0)?.toFixed(4)}
 									</VSCodeBadge>
+									<VSCodeBadge
+										style={{ opacity: tps !== null && tps !== undefined && tps > 0 ? 1 : 0 }}>
+										{Number(tps || 0).toFixed(1)} tokens/s
+									</VSCodeBadge>
+									<VSCodeBadge
+										style={{ opacity: latency !== null && latency !== undefined && latency > 0 ? 1 : 0 }}>
+										{Number(latency || 0)} ms
+									</VSCodeBadge>
 								</div>
 								<span className={`codicon codicon-chevron-${isExpanded ? "up" : "down"}`}></span>
 							</div>
@@ -1060,59 +1120,30 @@ export const ChatRowContent = ({
 					)
 				case "user_feedback":
 					return (
-						<div className="bg-vscode-editor-background border rounded-xs p-1 overflow-hidden whitespace-pre-wrap">
-							{isEditing ? (
-								<div className="flex flex-col gap-2 p-2">
-									<ChatTextArea
-										inputValue={editedContent}
-										setInputValue={setEditedContent}
-										sendingDisabled={false}
-										selectApiConfigDisabled={true}
-										placeholderText={t("chat:editMessage.placeholder")}
-										selectedImages={editImages}
-										setSelectedImages={setEditImages}
-										onSend={handleSaveEdit}
-										onSelectImages={handleSelectImages}
-										shouldDisableImages={false}
-										mode={editMode}
-										setMode={setEditMode}
-										modeShortcutText=""
-										isEditMode={true}
-										onCancel={handleCancelEdit}
-									/>
-								</div>
-							) : (
-								<div className="flex justify-between">
-									<div className="flex-grow px-2 py-1 wrap-anywhere">
-										<Mention text={message.text} withShadow />
-									</div>
-									<div className="flex">
-										<Button
-											variant="ghost"
-											size="icon"
-											className="shrink-0 hidden"
-											disabled={isStreaming}
-											onClick={(e) => {
-												e.stopPropagation()
-												handleEditClick()
-											}}>
-											<span className="codicon codicon-edit" />
-										</Button>
-										<Button
-											variant="ghost"
-											size="icon"
-											className="shrink-0"
-											disabled={isStreaming}
-											onClick={(e) => {
-												e.stopPropagation()
-												vscode.postMessage({ type: "deleteMessage", value: message.ts })
-											}}>
-											<span className="codicon codicon-trash" />
-										</Button>
-									</div>
+						// <div className="bg-vscode-editor-background border rounded-xs p-1 overflow-hidden whitespace-pre-wrap">
+						<div>
+							<div style={headerStyle}>
+								{icon}
+								{title}
+							</div>
+							<div className="flex justify-between">
+								<div className="flex-grow px-2 py-1 wrap-anywhere" style={{ color: "var(--vscode-charts-blue)" , paddingTop: 10 }}>
+									{/* <Mention text={message.text} withShadow /> */}
+									<Markdown markdown={message.text} partial={message.partial} />
 								</div>
-							)}
-							{!isEditing && message.images && message.images.length > 0 && (
+								<Button
+									variant="ghost"
+									size="icon"
+									className="shrink-0"
+									disabled={isStreaming}
+									onClick={(e) => {
+										e.stopPropagation()
+										vscode.postMessage({ type: "deleteMessage", value: message.ts })
+									}}>
+									<span className="codicon codicon-trash" />
+								</Button>
+							</div>
+							{message.images && message.images.length > 0 && (
 								<Thumbnails images={message.images} style={{ marginTop: "8px" }} />
 							)}
 						</div>
@@ -1165,6 +1196,25 @@ export const ChatRowContent = ({
 							checkpoint={message.checkpoint}
 						/>
 					)
+				case "save_memory":
+					if (message.partial) {
+						return <SavingMemoryRow />
+					}
+					return message.contextCondense ? <SaveMemoryRow {...message.contextCondense} /> : null
+				case "save_memory_error":
+					return <SaveMemoryErrorRow errorText={message.text} />
+				case "save_memory_tag":
+					return (<div>
+						<div style={headerStyle}>
+							{icon}
+							{title}
+						</div>
+						<div className="flex justify-between">
+							<div className="flex-grow px-2 py-1 wrap-anywhere" style={{ color: "#00a3af77" , paddingTop: 10 }}>
+								<Markdown markdown={message.text} partial={message.partial} />
+							</div>
+						</div>
+					</div>)
 				case "condense_context":
 					if (message.partial) {
 						return <CondensingContextRow />
@@ -1341,6 +1391,84 @@ export const ChatRowContent = ({
 				case "auto_approval_max_req_reached": {
 					return <AutoApprovedRequestLimitWarning message={message} />
 				}
+				case "web_search":
+					// Parse the message text to get the web search request
+					const webSearchJson = safeJsonParse<any>(message.text, {})
+
+					// Extract the response field if it exists
+					const { response: webSearchResponse, ...webSearchRequest } = webSearchJson
+
+					// Create the webSearch object with the response field
+					const webSearch = {
+						...webSearchRequest,
+						response: webSearchResponse,
+					}
+
+					const webSearchParameters = [
+						{
+							name: "query",
+							value: webSearch.query || "",
+							label: "搜索查询",
+						},
+					]
+
+					return (
+						<>
+							<div style={headerStyle}>
+								{icon}
+								{title}
+							</div>
+							<ToolExecution
+								executionId={message.ts.toString()}
+								toolName="web_search"
+								toolDisplayName="搜索列表"
+								parameters={webSearchParameters}
+								response={webSearch.response}
+								isPartial={message.partial}
+								status={webSearch.status}
+								error={webSearch.error}
+							/>
+						</>
+					)
+				case "url_fetch":
+					// Parse the message text to get the url fetch request
+					const urlFetchJson = safeJsonParse<any>(message.text, {})
+
+					// Extract the response field if it exists
+					const { response: urlFetchResponse, ...urlFetchRequest } = urlFetchJson
+
+					// Create the urlFetch object with the response field
+					const urlFetch = {
+						...urlFetchRequest,
+						response: urlFetchResponse,
+					}
+
+					const urlFetchParameters = [
+						{
+							name: "url",
+							value: urlFetch.url || "",
+							label: "URL地址",
+						},
+					]
+
+					return (
+						<>
+							<div style={headerStyle}>
+								{icon}
+								{title}
+							</div>
+							<ToolExecution
+								executionId={message.ts.toString()}
+								toolName="url_fetch"
+								toolDisplayName="内容列表"
+								parameters={urlFetchParameters}
+								response={urlFetch.response}
+								isPartial={message.partial}
+								status={urlFetch.status}
+								error={urlFetch.error}
+							/>
+						</>
+					)
 				default:
 					return null
 			}